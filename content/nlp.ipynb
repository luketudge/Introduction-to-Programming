{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language processing\n",
    "\n",
    "We have learned how to work with data organized as an [array](arrays.ipynb) of numbers, using the `numpy` package, or more generally as a [table](data_analysis.ipynb) of numeric and text columns, using `pandas`. We have also learned a bit about [working with image files](images.ipynb). The other major data format that you are likely to encounter in many computer programming tasks is natural, human-language text.\n",
    "\n",
    "In computing, people often refer to the languages that human beings use for everyday communication, such as English or Pirah√°, as 'natural' languages. This distinguishes them from programming languages like Python, and helps avoid confusion, for example when asking a computer person 'What language do you use at work?' Using computers to analyze natural language is often called 'Natural Language Processing' (NLP).\n",
    "\n",
    "Computers still have huge difficulty responding to natural language appropriately. Here we will introduce a few tools and techniques that can help if we need to write a computer program that takes natural language text as its input. These techniques are useful in many common programming tasks:\n",
    "\n",
    "* translating between natural languages\n",
    "* classifying texts by topic\n",
    "* identifying particular tones or styles, for example rude or offensive posts in a forum\n",
    "* creating chatbots or generating automated responses to customer queries\n",
    "* ... and even some genuinely useful things like [establishing the authorship of anonymous works of literature](https://dl.acm.org/doi/10.5555/1314498.1314541)\n",
    "\n",
    "Real-world natural language processing tasks like these are usually quite complex, and require a 'pipeline' of multiple techniques. As usual, we will only cover the basics. After our short introduction, you should know at least where to start if you later come to work with natural language text data.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Here is our toy task for this lesson.\n",
    "\n",
    "Let's imagine we have landed a job as an editor at a pretentious elitist newspaper, and we would like to write a program that helps us identify all the sentences in a text that violate one of the woefully misguided rules of the newspaper's style handbook. Let's take three example rules:\n",
    "\n",
    "* A preposition (such as for, to, etc.) is not a good thing to end a sentence with.\n",
    "* To boldly place an intervening word between the `to` and the `verb` in an infinitive is forbidden.\n",
    "* And you shouldn't begin a sentence with a conjunction (such as and, but, etc.)\n",
    "\n",
    "This isn't a completely unrealistic example. Talking right is something that many people still get [very excited](https://www.theguardian.com/books/booksblog/2015/oct/06/steven-pinker-alleged-rules-of-writing-superstitions) about.\n",
    "\n",
    "So that we have a large example text to work with, let's load the classic go-to text for all NLP examples ever, *Moby Dick*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moby Dick by Herman Melville 1851]\n",
      "\n",
      "\n",
      "ETYMOLOGY.\n",
      "\n",
      "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
      "\n",
      "The pale Usher--threadbare in coat, heart, body, and brain; I see him\n",
      "now.  He was ever dusting his old lexicons and grammars, with a queer\n",
      "handkerchief, mockingly embellished with all the gay flags of all the\n",
      "known nations of the world.  He loved to dust his old grammars; it\n",
      "somehow mildly reminded him of his mortality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "md = open(os.path.join('data', 'melville-moby_dick.txt')).read()\n",
    "\n",
    "print(md[:433])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String methods again\n",
    "\n",
    "Let's dive right in and just take a naive stab at the first rule, about not having a preposition at the end of a sentence. Ignoring for a moment any initial processing, such as splitting up the full text into sentences, we can first write a [function](glossary.ipynb#function) to determine whether or not a single sentence violates the rule.\n",
    "\n",
    "Remember the [main ingredients of a function](functions.ipynb#Defining-functions):\n",
    "\n",
    "* **The name of the function**. This function's job is just to say 'yes' or 'no'. For such functions, a good choice of name is some abbreviated form of a 'yes/no' question. We can go with `endswith_preposition`.\n",
    "\n",
    "* **Its input [arguments](glossary.ipynb#argument)**. This is easy. The single input argument is a [string](glossary.ipynb) containing the sentence.\n",
    "\n",
    "* **What steps it carries out (the 'body' of the function)**. There is room for some variation and choice of strategy here. But a simple start would be to split the sentence into words, get the final one, remove any punctuation characters, then compare it to a list of prepositions.\n",
    "\n",
    "* **The [return value](glossary.ipynb#return)**. We don't actually want to return the printed answer `'yes'` or `'no'`. If our function is to be useful as part of a bigger program, it needs to return the computer versions of 'yes' and 'no', a [boolean](glossary.ipynb#boolean), with `True` for 'yes the sentence violates the rule' and `False` for 'no it does not'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ' .,?!:;'\n",
    "prepositions = ['around', 'about', 'at', 'by', 'down', 'from', 'in', 'of', 'on', 'out', 'to', 'up', 'with']\n",
    "\n",
    "def endswith_preposition(sentence):\n",
    "    words = sentence.split()\n",
    "    final_word = words[-1].strip(punctuation)\n",
    "    return final_word.lower() in prepositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give our function a quick test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endswith_preposition('This is the sort of mindless pedantry I just cannot put up with!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endswith_preposition('This is the sort of mindless pedantry up with which I just cannot put!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works. But you can probably already spot a few deficiencies. For example, there are other punctuation characters that might end a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endswith_preposition('I said \"This is the sort of mindless pedantry I just cannot put up with!\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk\n",
    "\n",
    "We have a similar problem with our list of prepositions. It is far from complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endswith_preposition(\"Now that's the kind of pedantry I can get behind!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions aren't going to be of much help fixing this second limitation of our function. We could just include more prepositions in our list. But there are [a lot of prepositions](https://en.wikipedia.org/wiki/List_of_English_prepositions) that we would need to take into account.\n",
    "\n",
    "As we have seen a few times before, when we encounter what seems like a difficult but common problem, there may be some tools already out there that can help save us from re-inventing the wheel. There are lots of Python [packages](glossary.ipynb#package) for NLP, which apply various techniques ranging from simple string processing like in our example function above, to something more like artificial intelligence.\n",
    "\n",
    "We will look at just one NLP package, called `nltk`, which stands for 'natural language tool kit'. The tools provided by `nltk` are a bit more complex than our example function, but still simple enough to be suitable for an introduction to NLP. Indeed, `nltk` was originally created to teach linguists how to do computing with Python, and it accompanies a book about Python and NLP, which is [free to read online](http://www.nltk.org/book).\n",
    "\n",
    "`nltk` is included in the default Anaconda installation, so if you have Anaconda then you will have it already. Let's import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "sentence = 'This is the sort of mindless pedantry I just cannot put up with!'\n",
    "\n",
    "words = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/lt/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/lt/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'mindless',\n",
       " 'pedantry',\n",
       " 'I',\n",
       " 'just',\n",
       " 'can',\n",
       " 'not',\n",
       " 'put',\n",
       " 'up',\n",
       " 'with',\n",
       " '!']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('sort', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('mindless', 'ADJ'),\n",
       " ('pedantry', 'NOUN'),\n",
       " ('I', 'PRON'),\n",
       " ('just', 'ADV'),\n",
       " ('can', 'VERB'),\n",
       " ('not', 'ADV'),\n",
       " ('put', 'VERB'),\n",
       " ('up', 'PRT'),\n",
       " ('with', 'ADP'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words, tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
